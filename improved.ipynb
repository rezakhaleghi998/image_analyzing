{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Object Detection for Image Analysis\n",
    "\n",
    "This notebook demonstrates the use of YOLO (You Only Look Once) for object detection in images. We'll work with YOLOv8 to detect objects in various images and analyze the results.\n",
    "\n",
    "## Table of Contents\n",
    "1. Setup and Dependencies\n",
    "2. Loading the YOLO Model\n",
    "3. Object Detection on Sample Images\n",
    "4. Visualizing Results\n",
    "5. Advanced Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, we'll install and import the necessary libraries for our object detection task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install ultralytics package which contains YOLO implementations\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "from IPython.display import display, Image\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Set display parameters for better visualization\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the YOLO Model\n",
    "\n",
    "Here we load YOLOv8, a state-of-the-art object detection model. YOLOv8 offers excellent performance for real-time object detection with a good balance between speed and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the YOLOv8 model (nano version)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Print model information to verify it's loaded correctly\n",
    "print(f\"Model loaded: {model}\")\n",
    "print(f\"Model task: {model.task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Object Detection on Sample Images\n",
    "\n",
    "Let's start by downloading a sample image and performing object detection on it. We'll visualize both the original image and the detection results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download a sample image\n",
    "!wget -q https://ultralytics.com/images/bus.jpg -O bus.jpg\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(10, 8))\n",
    "img = cv2.imread('bus.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for display\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Object Detection\n",
    "\n",
    "Now we'll run the YOLO model on our image to detect objects. The model will identify various objects and provide bounding boxes, class labels, and confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run prediction on the sample image\n",
    "results = model('bus.jpg')\n",
    "\n",
    "# Display the results\n",
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im_array = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(im_array)\n",
    "    plt.title('Object Detection Results', fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Detection Results\n",
    "\n",
    "Let's analyze the detection results to understand what objects were found and their confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze the detection results\n",
    "result = results[0]  # Get the first result\n",
    "\n",
    "# Extract bounding boxes, confidence scores, and class names\n",
    "boxes = result.boxes\n",
    "print(f\"Number of objects detected: {len(boxes)}\")\n",
    "\n",
    "# Display detected objects with confidence scores\n",
    "detected_objects = {}\n",
    "\n",
    "for box in boxes:\n",
    "    # Get class name\n",
    "    class_id = int(box.cls.item())\n",
    "    class_name = result.names[class_id]\n",
    "    \n",
    "    # Get confidence score\n",
    "    confidence = float(box.conf.item())\n",
    "    \n",
    "    # Store in our dictionary\n",
    "    if class_name in detected_objects:\n",
    "        detected_objects[class_name].append(confidence)\n",
    "    else:\n",
    "        detected_objects[class_name] = [confidence]\n",
    "\n",
    "# Print detection summary\n",
    "print(\"\\nDetection Summary:\")\n",
    "for obj, confidences in detected_objects.items():\n",
    "    avg_conf = sum(confidences) / len(confidences)\n",
    "    print(f\"- {obj}: {len(confidences)} instances, Average confidence: {avg_conf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing with Multiple Images\n",
    "\n",
    "Let's test our model on additional images to see how well it performs with different scenes and objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download additional test images\n",
    "!wget -q https://ultralytics.com/images/zidane.jpg -O zidane.jpg\n",
    "!wget -q https://ultralytics.com/images/people.jpg -O people.jpg\n",
    "\n",
    "# Create a function to process and display images\n",
    "def process_image(image_path):\n",
    "    # Run inference\n",
    "    results = model(image_path)\n",
    "    result = results[0]\n",
    "    \n",
    "    # Get original image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get annotated image\n",
    "    annotated_img = result.plot()\n",
    "    annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Count detected objects\n",
    "    detected_counts = {}\n",
    "    for box in result.boxes:\n",
    "        class_id = int(box.cls.item())\n",
    "        class_name = result.names[class_id]\n",
    "        if class_name in detected_counts:\n",
    "            detected_counts[class_name] += 1\n",
    "        else:\n",
    "            detected_counts[class_name] = 1\n",
    "    \n",
    "    # Display images side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=16)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(annotated_img)\n",
    "    ax2.set_title('Detection Results', fontsize=16)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detection summary\n",
    "    print(f\"Detection summary for {os.path.basename(image_path)}:\")\n",
    "    for obj, count in detected_counts.items():\n",
    "        print(f\"- {obj}: {count} instances\")\n",
    "    print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Process each image\n",
    "print(\"Processing image 1: zidane.jpg\")\n",
    "result1 = process_image('zidane.jpg')\n",
    "\n",
    "print(\"\\nProcessing image 2: people.jpg\")\n",
    "result2 = process_image('people.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Applications\n",
    "\n",
    "### Visualizing Bounding Boxes and Confidences\n",
    "\n",
    "Let's create a more detailed visualization showing each detected object with its bounding box coordinates and confidence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def advanced_visualization(image_path):\n",
    "    # Run detection\n",
    "    results = model(image_path)\n",
    "    result = results[0]\n",
    "    \n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get dimensions\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    ax.imshow(img_rgb)\n",
    "    \n",
    "    # Colors for different classes\n",
    "    np.random.seed(42)  # for consistent colors\n",
    "    colors = {}\n",
    "    \n",
    "    # Plot each detection\n",
    "    for box in result.boxes:\n",
    "        # Get box coordinates\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        # Get class and confidence\n",
    "        class_id = int(box.cls.item())\n",
    "        class_name = result.names[class_id]\n",
    "        confidence = float(box.conf.item())\n",
    "        \n",
    "        # Get color for class\n",
    "        if class_name not in colors:\n",
    "            colors[class_name] = np.random.rand(3,)\n",
    "        color = colors[class_name]\n",
    "        \n",
    "        # Plot rectangle\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, \n",
    "                          edgecolor=color, linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        label = f\"{class_name}: {confidence:.2f}\"\n",
    "        ax.text(x1, y1-10, label, fontsize=10, bbox=dict(facecolor=color, alpha=0.5))\n",
    "    \n",
    "    ax.set_title(f\"Advanced Visualization: {os.path.basename(image_path)}\", fontsize=16)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed information\n",
    "    print(f\"\\nDetailed detection information for {os.path.basename(image_path)}:\")\n",
    "    for i, box in enumerate(result.boxes):\n",
    "        class_id = int(box.cls.item())\n",
    "        class_name = result.names[class_id]\n",
    "        confidence = float(box.conf.item())\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "        \n",
    "        print(f\"Detection {i+1}:\")\n",
    "        print(f\"  - Class: {class_name}\")\n",
    "        print(f\"  - Confidence: {confidence:.4f}\")\n",
    "        print(f\"  - Bounding Box: [x1={x1:.1f}, y1={y1:.1f}, x2={x2:.1f}, y2={y2:.1f}]\")\n",
    "        print(f\"  - Box Width: {x2-x1:.1f}, Height: {y2-y1:.1f}\")\n",
    "        print()\n",
    "\n",
    "# Apply advanced visualization to our images\n",
    "print(\"Advanced visualization for bus.jpg:\")\n",
    "advanced_visualization('bus.jpg')\n",
    "\n",
    "print(\"\\nAdvanced visualization for zidane.jpg:\")\n",
    "advanced_visualization('zidane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Image Processing\n",
    "\n",
    "Now let's create functionality to process custom images that you can upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload and process custom images\n",
    "from google.colab import files\n",
    "\n",
    "def process_custom_images():\n",
    "    print(\"Please upload an image file:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"\\nProcessing {filename}...\")\n",
    "        \n",
    "        # Run detection\n",
    "        results = model(filename)\n",
    "        result = results[0]\n",
    "        \n",
    "        # Display results\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "        \n",
    "        # Original image\n",
    "        img = cv2.imread(filename)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax1.imshow(img_rgb)\n",
    "        ax1.set_title('Original Image', fontsize=16)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Annotated image\n",
    "        annotated_img = result.plot()\n",
    "        annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "        ax2.imshow(annotated_img)\n",
    "        ax2.set_title('Detection Results', fontsize=16)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Display detection summary\n",
    "        detected_counts = {}\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls.item())\n",
    "            class_name = result.names[class_id]\n",
    "            confidence = float(box.conf.item())\n",
    "            \n",
    "            if class_name in detected_counts:\n",
    "                detected_counts[class_name][0] += 1\n",
    "                detected_counts[class_name][1].append(confidence)\n",
    "            else:\n",
    "                detected_counts[class_name] = [1, [confidence]]\n",
    "        \n",
    "        print(f\"Detection results for {filename}:\")\n",
    "        for obj, (count, confidences) in detected_counts.items():\n",
    "            avg_conf = sum(confidences) / len(confidences)\n",
    "            print(f\"- {obj}: {count} instances, Avg. confidence: {avg_conf:.2f}\")\n",
    "\n",
    "# Run the function to process custom images (uncomment to use)\n",
    "# process_custom_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis of Detections\n",
    "\n",
    "Let's analyze the distribution of detected objects across our sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def statistical_analysis(image_paths):\n",
    "    all_detections = {}\n",
    "    image_stats = {}\n",
    "    \n",
    "    # Process each image\n",
    "    for path in image_paths:\n",
    "        results = model(path)\n",
    "        result = results[0]\n",
    "        image_name = os.path.basename(path)\n",
    "        \n",
    "        # Store detections for this image\n",
    "        image_stats[image_name] = {}\n",
    "        \n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls.item())\n",
    "            class_name = result.names[class_id]\n",
    "            confidence = float(box.conf.item())\n",
    "            \n",
    "            # Update image stats\n",
    "            if class_name in image_stats[image_name]:\n",
    "                image_stats[image_name][class_name][0] += 1\n",
    "                image_stats[image_name][class_name][1].append(confidence)\n",
    "            else:\n",
    "                image_stats[image_name][class_name] = [1, [confidence]]\n",
    "                \n",
    "            # Update overall stats\n",
    "            if class_name in all_detections:\n",
    "                all_detections[class_name] += 1\n",
    "            else:\n",
    "                all_detections[class_name] = 1\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    print(\"Object Detection Summary Across Images:\")\n",
    "    for image, stats in image_stats.items():\n",
    "        print(f\"\\n{image}:\")\n",
    "        for obj, (count, confidences) in stats.items():\n",
    "            avg_conf = sum(confidences) / len(confidences)\n",
    "            print(f\"  - {obj}: {count} instances, Avg. confidence: {avg_conf:.2f}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Sort classes by number of instances\n",
    "    sorted_detections = sorted(all_detections.items(), key=lambda x: x[1], reverse=True)\n",
    "    classes = [item[0] for item in sorted_detections]\n",
    "    counts = [item[1] for item in sorted_detections]\n",
    "    \n",
    "    plt.bar(classes, counts, color='skyblue')\n",
    "    plt.title(\"Object Classes Detected Across All Images\", fontsize=16)\n",
    "    plt.xlabel(\"Object Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return all_detections, image_stats\n",
    "\n",
    "# Perform statistical analysis on our images\n",
    "image_paths = ['bus.jpg', 'zidane.jpg', 'people.jpg']\n",
    "all_detections, image_stats = statistical_analysis(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've successfully implemented object detection using YOLOv8. We've demonstrated:\n",
    "\n",
    "1. Setting up the YOLO model\n",
    "2. Performing object detection on sample images\n",
    "3. Analyzing and visualizing detection results\n",
    "4. Processing custom images\n",
    "5. Statistical analysis of detections across multiple images\n",
    "\n",
    "### Potential Next Steps:\n",
    "\n",
    "1. **Fine-tuning the model**: Train YOLO on your own dataset for customized object detection\n",
    "2. **Video processing**: Extend the functionality to process videos instead of just images\n",
    "3. **Real-time detection**: Implement webcam-based real-time object detection\n",
    "4. **Specialized applications**: Focus on specific use cases like person tracking or vehicle counting\n",
    "5. **Integration**: Integrate this object detection system with other applications or services\n",
    "\n",
    "These enhancements would build upon the foundation we've established in this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
